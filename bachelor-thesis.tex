\documentclass[times,specification,annotation]{itmo-student-thesis}

%% Опции пакета:
%% - specification - если есть, генерируется задание, иначе не генерируется
%% - annotation - если есть, генерируется аннотация, иначе не генерируется
%% - times - делает все шрифтом Times New Roman, собирается с помощью xelatex
%% - pscyr - делает все шрифтом Times New Roman, требует пакета pscyr.

%% Делает запятую в формулах более интеллектуальной, например:
%% $1,5x$ будет читаться как полтора икса, а не один запятая пять иксов.
%% Однако если написать $1, 5x$, то все будет как прежде.
\usepackage{icomma}

%% Один из пакетов, позволяющий делать таблицы на всю ширину текста.
\usepackage{tabularx}

%% Указываем файл с библиографией.
\addbibresource{bachelor-thesis.bib}

\begin{document}

\studygroup{M3439}
\title{Обучение метрики похожести сообществ с помощью выделения
векторного представления}
\author{Зернов Глеб Сергеевич}{Зернов Г.С.}
\supervisor{Сметанников Иван Борисович}{Сметанников И.Б.}{к.техн.н.}{ассистент, факультет информационных технологий и программирования, Университет ИТМО}
\publishyear{2019}
%% Дата выдачи задания. Можно не указывать, тогда надо будет заполнить от руки.
\startdate{18}{декабря}{2018}
%% Срок сдачи студентом работы. Можно не указывать, тогда надо будет заполнить от руки.
\finishdate{6}{мая}{2019}
%% Дата защиты. Можно не указывать, тогда надо будет заполнить от руки.
\defencedate{}{}{2019}

\addconsultant{Попов А.Л.}{магистр}

\secretary{Павлова О.Н.}

%% Задание
%%% Техническое задание и исходные данные к работе
\technicalspec{Разработать модель, которая позволит представить сообщества социальной сети в
виде векторов. Модель необходимо обучить и протестировать на анонимных неразмеченных
сессионных данных из социальной сети «Вконтакте». Необходимо проанализировать
результаты и сравнить предлагаемое решение с альтернативными методами.}

%%% Содержание выпускной квалификационной работы (перечень подлежащих разработке вопросов)
\plannedcontents{
\begin{enumerate}
\item[1.] Описание предметной области. Обзор существующих алгоритмов.
\item[2.]  Описание алгоритма векторного представления сообществ
\item[3.]  Анализ результатов, сравнение с существующими решениями.
\end{enumerate}}

%%% Исходные материалы и пособия 
\plannedsources{}

%%% Цель исследования
\researchaim{Реализация алгоритма представления сообществ социальной сети в виде векторов.}

%%% Задачи, решаемые в ВКР
\researchtargets{\begin{enumerate}
    \item Обзор существующих подходов.
    \item Разработка алгоритма
выделения векторного представления сообществ по сессионным анонимным неразмеченным
данным. 
    \item Анализ полученных результатов.
\end{enumerate}}

%%% Использование современных пакетов компьютерных программ и технологий
\addadvancedsoftware{Язык программирования \texttt{Python}}{
%%% \ref{sec:tables}, Приложения~\ref{sec:app:1}, \ref{sec:app:2}
2.3 – 3.3}
\addadvancedsoftware{Программное средство \texttt{Jupyter Notebook}}{2.3 – 3.3}
\addadvancedsoftware{Библиотека \texttt{Pytorch}}{2.3 – 2.6}
\addadvancedsoftware{Библиотека \texttt{Sklearn}}{3.1 – 3.3}
\addadvancedsoftware{Библиотека \texttt{Matplotlib}}{3.1}

%%% Краткая характеристика полученных результатов 
\researchsummary{Исследованы существующие решения данной задачи. Реализован алгоритм, позволяющий
решить поставленную задачу. Проведено сравнение предложенного решения с существующими
путем решения дополнительных задач классификации с использованием результатов работы
моделей в качестве входных данных.}

%%% Гранты, полученные при выполнении работы 
\researchfunding{При выполнении работы грантов получено не было.}

%%% Наличие публикаций и выступлений на конференциях по теме выпускной работы
\researchpublications{Нет}

%% Эта команда генерирует титульный лист и аннотацию.
\maketitle{Бакалавр}

%% Оглавление
\tableofcontents

%% Макрос для введения. Совместим со старым стилевиком.
\startprefacepage

Обычно объекты из реального мира представимы в виде набора некоторого
количества признаков, численные значения которых, в свою очередь, можно
представить в виде вектора. Таким образом, мы можем получить представление о
положении объектов относительно друг друга в полученном пространстве,
сохраняя при этом знания о конкретных признаках каждого объекта. Такие
векторы можно использовать в ряде алгоритмов машинного обучения, исходя из
простого правила: чем ближе два вектора друг к другу, тем более похожи между
собой два объекта.

Однако, существует возможность столкнуться с рядом проблем при попытке
представить объекты в виде векторов. К примеру, полученные векторы могут не
коррелировать с положением дел в реальном мире. В таком случае, выбранные
нами векторы не подходят для алгоритмов машинного обучения, поскольку
алгоритм не будет способен сопоставить положение векторов в простратсве с картиной
реального мира. Кроме того, какие-то сущности имеют либо слишком большое
число признаков, и понять, какие признаки стоит добавить в конечный вектор, а
какие отбросить, бывает крайне трудной задачей.

Решением этих проблем выступает синтетический вектор (эмбеддинг), элементы
которого сами по себе не имеют отношение к какому-то конкретному признаку, но
в совокупности данные векторы подходят для описания объекта.

%% Начало содержательной части.
\chapter{ОПИСАНИЕ ПРЕДМЕНТОЙ ОБЛАСТИ}

\startrelatedwork

\section{Основные определения}

TODO: больше определений и вводных понятий

Векторное представление или эмбеддинг (англ. Embedding) --- отображение
множества объектов на пространство векторов с сохранением некоторой
структуры за объектами.

\section{Постановка задачи}\label{sec:intro}

«Вконтакте» --- одна из крупнейших социальных сетей СНГ и самая
популярная соц. сеть в России. «Вконтакте» на ряду с многими другими
социальными сетями имеет внутри себя объединения пользователей по интересам,
называемое сообществами. Пользователи имеют возможность подписаться на
интересуемое их сообщество для более удобного взаимодействия с информацией
сообщества, а также отписаться от него. Сообщества могут добавлять на свою
страницу записи (текст, картинки, видео и т. д.), которые пользователи могут
помечать как понравившиеся («лайки»), комментировать и прочее.

Существенной сложностью работы с сообществами является число сообществ (миллионы), каждое из которых может состоять из миллионов пользователей, и содержать миллионы записей.  

Таким образом, полная информация о сообществе --- это огромный массив
данных, предоставляя который полностью некоторой модели машинного обучения,
мы не только существенно увеличиваем размер необходимого объема памяти для хранения этой информации, но и замедляем работу самого алгоритма, что делает потенциальный алгоритм бесполезным на практике.

Выходом из этой ситуации является некоторое более емкое представление сообщества без потери интересующей нас информации.

Главная задача, решаемая в моей работе, --- разработать алгоритм выделения универсального векторного представление сообществ небольшой размерности. 

Полученные векторы имеют практическую ценность. Например, они могут быть использованы в
качестве входных данных другой модели и проанализированы с целью
получить представление о сходстве пар сообществ между собой. Такие векторы содержат большое количество информации в сжатом виде, в отличие, от, например, классического one-hot (подробнее в \ref{sec:nlp-intro}) векторного представления объектов.

\subsection{Формат входных данных}

Компанией были предоставлены анонимные сессионные действия пользователей за небольшой промежуток времени (около 3 месяцев) двух видов: подписки и отписки на сообщества.

Таким образом, в моем распоряжении есть список сессий (числом 1 000 000), каждая сессия --- это список действий некоторого пользователя, элементами списка является идентификатор сообщества (id) и маркер действия (подписка/отписка)

После фильтрации данных общее число сессий было сокращено до 500 000, число уникальных групп до 11 000.    

\section{Обзор существующих решений}

Представление сущностей в виде эмбеддингов является довольно распространенной задачей. Часто такие векторы являются продуктом работы некоторого алгоритма, решающего другую задачу. 

\subsection{Алгоритм факторизации матриц в рекомендательных системах.}\label{sec:als}

Персонализация пользовательского контента является одной из основопологающих частей систем, предоставляющих такой контент конечным пользователям. Лидеры интернет-торговли или интернет-услуг особенно заинтересованы в таких алгоритмах, поскольку позволяет увеличить пользователский отклик.
В общем случае, рекомендательные системы берут за основу две стратегии: фильтрация контента (content filtering) и коллаборативная фильтрация (collaborative filtering)
  
Главная идея за фильтрацией контента состоит в том, чтобы создать профиль для каждого пользователя или продукта с целью охарактеризовать сущность. Например, в качестве профиля фильма могут выступать жанр, актеры, кассовые сборы и т.д.

Альтернативный вариант, коллаборативная фильтрация, опирается на действия пользователей, сделанных в прошлом. Такие алгоритмы анализируют статистические связи между пользователями, продуктами, их взаимодействиями и дают рекомендации, основываясь на исторических данных.  Большим плюсом таких систем является независимость от домена, в котором они применяются.

Одним из самых распространных на данный момент времени алгоритмов в сфере рекоммендательных систем является алгоритм факторизации матриц \cite{koren2009}, относящийся к группе алгоритмов коллаборативной фильтрации.

Модель матричной факторизации переносит пользователей и продукты в пространство признаков размерности $n$. Таким образом, продукт $p$ пресдавим в виде вектора $a_{p} \in \mathbb{R}^n$ , а пользователь $u$ в виде вектора $b_{u} \in \mathbb{R}^n$. Для продукта каждый из элементов вектора отвечает за то, насколько каждый признак характерен для  этого продукта. В то время для пользователя элементы вектора показывают, насколько пользователю интерес признак.

Это позволяет задать оценку пользователя $u$ продукта $p$ в виде формулы

$r_{ui} = a_{i}^{T}b_{u}$

Таким образом, зная матрицу пользовательских оценок $R$ можно разложить ее на произведение матриц $A$ и $B$, отвечающих за векторное произведение продуктов и пользователей соответственно.

$R = A^TB$

В рамках нашей задачи составим матрицу оценок следующим образом: для подписки пользователя $i$ на сообщество $j$ поставим единицу на эту позицию $R_{ij} = 1$, аналогично для отписки $R_{ij} = - 1$. В случае отсутствия действий пользователя для сообщества оценка будет равна нулю.


\subsection{Обзор алгоритма LDA}\label{sec:lda}

TODO: написать обзор + сравнить результаты в главе 3

\section{Модели естественного языка}\label{sec:nlp-intro}

Для множества алгоримов обработки естественного языка (Natural Language Processing, NLP) некие специализированные цели алгоритма могут быть обобщены на задачу нахождения значений вероятностей для последовательностей слов.
Таким образом, развитие моделей естественного языка шло путем выявления статистических свойств слов и нахождения зависимостей между ними.

Традиционно такие подходы представляли каждое слово в виде one-hot вектора, где размерность вектора каждого слова равна длине словаря, а значения элементов равны 1, если номер элемента совпадает с позицией слова в словаре, и 0 иначе.  

Существенным недостатком такого подхода является наложение ограничений на практическое применение алгоритмов, в связи с большой размерностью объектов и разряженности данных, приводящих к ощутимой потери производительности.

Исследователями были предложены модели на основе нейронных сетей\cite{turian2010}, которые позволяют решить эти проблемы путем представления слов в виде векторов гораздо меньшей размерности. Такие модели основываются на гипотезе о том, что близкие друг к другу слова в предложениях статистически более зависимы.

Исторически, неэффективность обучения моделей нейронных сетей была главным препятствием на пути к применению таких алгоритмов на практике, поскольку словарь может достигать миллионов слов. Однако предложенные в \cite{mikolov2013efficient} и \cite{mikolov2013distributed} модели оказались достаточно хорошо масштабируемыми и могут быть эффективно использованы на практике. Алгоритмы оказались крайне результативными и эксперименты показали, что модели способы выявлять синтаксические и семантические связи между словами в больших корпусах слов. 

Концептуальность такого представления объектов вышла за рамки задач естественного языка и была применена в областях, с ним не связанных. Так были предложены алгоритмы векторного представления продуктов \cite{grbovic2015commerce}, рекоммендательных систем \cite{ozsoy2016word} и прочие.

%\subsection{Обзор алгоритма word2vec}\label{sec:word2vec}

%Word2vec\cite{mikolov2013efficient} --- нейронная сеть с одним скрытым слоем, позволяющая
%представлять слова в виде векторов в качестве дополнительного продукта после
%обучения самой модели. Основная гипотеза, на которой строится модель, --- слова,
%встречающиеся в одном и том же (или похожем) контексте, будут похожи между
%собой (либо одинаковыми по смыслу).

%Word2vec набрал большую популярность в научном сообществе. Было показано, что данный алгоритм представляет интерес не только в рамках nature language processing, но и в других, не связанных с естественным языком, категориях. Представленный алгоритм позволяет выявлять синтаксические и семантические связи слов, что представляет определенный интерес в рамках других задач. Так, концепт 

%Так в \cite{grbovic2015commerce} был описан алгоритм, позволяющий

%Далее в главе \ref{sec:algo} будет рассмотрена модификация алгоритма word2vec для решения задачи в рамках сообществ социальной сети.

\finishrelatedwork

\chapter{ОПИСАНИЕ АЛГОРИТМА ВЫДЕЛЕНИЯ ВЕКТОРНОГО ПРЕДСТАВЛЕНИЯ СООБЩЕСТВ}

В данной главе мы рассмотрим алгоритм, позволяющий выделять векторы
сущностей, информация о которых представлена в виде сессии взаимодействия
пользователей с этими сущностями (положительные и отрицательные отклики).
Также будет рассмотрена реализация алгоритма на примере сессионных данных
пользователей «Вконтакте».

% Сначала будут рассмотрены методы применения алгоритмов описанных в \ref{sec:als} и \ref{sec:lda} в рамках поставленной задачи.  Затем будет рассмотрена возможность модификации алгоритма \ref{sec:word2vec} для решения поставленной задачи. В конце будет описан конечный вариант алгоритма, базирующийся на \ref{sec:word2vec}.

\section{Описание алгоритма}\label{sec:algo}

\section{Модификации функции подсчета вероятности }
Как было написано в пункте \ref{sec:algo}, классическая реализация
алгоритма word2vec пытается максимизировать вероятность, задаваемой функцией
Softmax. Существенным недостатком этой функции является сложность ее
вычисления, обуславливаемая большим числом операций (пропорциональных
размеру словаря или числу групп).



Популярной альтернативой Softmax является Noise Contrastive Estimation ~\cite{mikolov2013distributed}.

TODO: NCE ФОРМУЛА

Представленная функция позволяет сменить постановку задачи на научиться
отличать целевое слово Wo от случайно выбранного слова из распределения шума
P. Таким образом, NCE позволяет приблизительно максимизировать логарифм
вероятности, задаваемый с помощью Softmax. Однако в данной работе гораздо
более важным фактором выступают негативные события, в связи с чем NCE
работает хуже, чем подход, описанный далее.

Альтернатива подсчета полных вероятностей с помощью Softmax --- это
негативное семплирование. Формула, представленная в ~\cite{airbnb} может быть
адаптирована в рамках текущей задачи как

TODO: Sigmoid формула (1)

Где T --- целевой объект (сообщество), X --- множество позитивных событий
контекста (подписки на сообщества), Y --- множество негативных событий
контекста (отписки от сообщества), Z --- множество случайных негативных
событий, не входящих в X и Y. Значит, наша задача --- максимизировать данную
функцию на каждом шаге обучения, повышая, таким образом, вероятность для
позитивных событий и понижая для негативных.

\section{ Негативное семплирование}
Мною были опробованы различные способы преставления негативных
семплов. Сначала я попробовал упрощенную версию формулы (1), опустив
последний член выражения. Таким образом, в качестве негативных сигналов
выступали только отписки. К сожалению, в таком случае чрезвычайно сильное
влияние оказывает начальное состояние векторов (случайное), поскольку число
сообществ в данных достаточно большое, частая ситуация, когда два сообщества
не встречаются одновременно ни в подписках, ни в отписках. Таким образом,
модель в процессе обучения не получает данных о том, что сообщества, вероятно,
не похожи друг на друга (не встречаются в одинаковых контекстах). Поэтому
вектора двух сообществ не удаляются друг относительно друга достаточно сильно
в результирующем пространстве.

Гораздо лучшие результаты были получены при использовании случайных
негативных сигналов вместе с отписками. Так, сообщества, не разделяющие общих
контекстов, удаляются быстрее друг от друга. Кроме того, отписки являются
сильным и постоянным сигналом для модели.

\section{Представление данных для модели}
«Вконтакте» предоставил мне анонимизированные данные пользователей, а
именно: список сессий, состоящих из подписок и отписок от сообществ какого-то
пользователя за небольшой промежуток времени (2-3 месяца), общим размером
примерно 1 000 000. Вопрос заключается в том, как подать данные для модели
наилучшим образом?

Для каждой сессии будем составлять пакеты, состоящие из целевого
сообщества, его контекста и негативных сигналов. Негативные семплы, как было
описано выше, состоят из отписок (общие для всей сессии и, как следствие,
каждого пакета) и случайных элементов, не входящих в сессию (генерируются для
каждого пакета).

Целевые сообщества будем получать, итерируясь по сессии, а способы
получения контекста будут описаны ниже. Таким образом, для каждой сессии
получим список пакетов длины сессии, которые можно передать в модель для
обучения.

Первый и самый простой подход, использующийся в множестве NLP
алгоритмов, это представить контекст в виде нескольких N-gram’о. То есть, задав
N, в качестве контекста будем передавать ближайшие N сообществ к целевому
(будем смотреть на сообщества, стоящие справа и слева от данного). Данный
способ показывает себя очень плохо на наших данных, поскольку подписка
достаточно редкое явление и является сильным сигналом, при том часть сигналов
(отстоящих на > N сессий от целевой) будет игнорироваться. С другой стороны,
для слабых и более частых событий (например, лайки пользователей или клики по
ссылкам) N-gram имеет преимущество в скорости и более устойчив к
переобучению.

Другим способом является передача всей сессии в модель. Таким образом,
контекстом будет выступать вся сессия за исключением целевого сообщества.
Однако было замечено, что в данных присутствует небольшое число очень
длинных сессий, которые никак не обрабатываются данным методом и негативно
влияют на обучение (поскольку в таком случае далеко стоящие друг от друга
события в сессии являются шумом)

Решением проблемы предыдущего способа может быть нарезка больших
сессий на несколько маленьких. Однако, на практике, такие сессии чаще всего
являются достаточно шумными.

Лучшего всего себя показал метод фильтрования чрезмерно длинных сессий
и передачи сессии в модель используя способ, описанный выше.

\section{Конечная модель}

Итоговая модель обучается следующим образом: получив на вход пакет из
целевого сообщества, списка позитивных и негативных сигналов, посчитаем
значение функции (1). Посчитав градиент, обновим веса входной и выходной
матриц, заканчивая шаг обучения.

Интересующий нас результат находится в первой матрице, которая
представляет из себя векторы сообществ, т. е. в строке N содержится векторное
представления сообщества N. Дополнительная (выходная) матрица
интерпретируется как векторное представление контекстов и не имеет большой
прикладной ценности.

\chapterconclusion

Мы обучили алгоритм, результатом которого является матрица векторного
представления сообществ. Предлагаемый алгоритм имеет ряд довольно весомых
преимуществ по сравнению с альтернативными подходами. 

Полученные векторы
имеют малую размерность (которую можно задать в качестве параметра), что
делает применение векторов в качестве входных данных какой-либо другой
модели более удобным. 

При построении векторов учитывается сессионная и
коллаборативная информация, таким образом, полученный результат будет
учитывать как сходство сообществ в похожих контекстах, так и давность данных
(предпочтения пользователя могут меняться со временем). 

Отдельно стоит отметить возможность работы алгоритма на анонимизированных данных, когда
нам не известно ничего про пользователя, кроме нескольких последних действий,
которые он сделал. Например, неавторизованный пользователь.

Кроме того, входные данные для модели не требуют дополнительной ручной разметки. Все, что нужно модели для работы, --- пользовательские действия, которые могут быть никак не обработаны. Таким образом, использование модели в реальной системе является крайне простым.

\chapter{РЕЗУЛЬТАТЫ ЭКСПЕРИМЕНТОВ}

В качестве дополнительной задачи позволяющей понять, что полученные
векторы действительно несут полезную информацию (правильным образом
представляют положение сообществ в пространстве) я решил ряд подзадач
описанных в 3.2 --- 3.Х и сравнил полученные результаты с альтернативными
алгоритмами, описанными в первой главе.

\section{Кластеризация полученных векторов}

Векторы, полученные из модели, описанной в главе 2, можно представить в
более удобном формате для анализа. Например, их можно кластеризировать и
рассмотреть несколько кластеров. В качестве алгоритма кластеризации был
использован k-means, результатом работы которого является разбиение итоговых
векторов на 256 кластеров. Для визуализации был применен алгоритм t-SNE,
позволяющий понизить размерность векторов до 2, для последующего
представления с помощью библиотеки matplotplib. (См. рисунок 1)

TODO: рисунок 1

Рассмотрим более подробно группы кластеров, отмеченными на рис. 1
цифрами 1, 2 и 3.

Группа 1 имеет выраженную особенность в виде удаленности от остальных
точек. Действительно, при более близком рассмотрении сообществ первой группы,
становится ясно, что они сильно специфичны: это сообщества продавцов и
покупателей ТК «Садовод». Значит, модель умеет отличать сообщества узко
направленной тематики и помещать их рядом в конечном векторном пространстве.

Группа 2 является скоплением кластеров сообществ пользователей
Казахстана, ведущихся на казахском языке. Стоит отметить, что данная группа
также отстоит от прочих сообществ и, кроме того, является достаточно большой
(данная группа содержит более 10 различных кластеров). Таким образом,
полученная модель умеет выделять сообщества пользователей, относящихся к
меньшинству пользователей платформы. (Пользователей, говорящих на казахском
языке, значительно меньше русскоговорящих)

Группа 3 содержит в себе два скопления кластеров, находящихся довольно
близко друг к другу и представляет из себя поклонников восточной культуры.
Представленные кластеры в первом скоплении являются сообществами о Корее и
корейской популярной музыки, во втором – сообщества о Японии и японской
анимации. Так, модель умеет не только группировать сообщества близкие по
тематике (Корея и корейская музыка), но и схожие по типажу (азиатская культура).

TODO: переписать все что сверху

Отдельно приведем пример кластера, связанного с изучением английского
языка в таблице 1. Полная ссылка, указанная в таблице, имеет вид
(vk.com/[значение])

TODO: таблица

\section{Обучение алгоритма классификации сообществ}

Сообщества «Вконтакте» имеют категории, задаваемые администраторами
(например, спорт, СМИ и т. д.). Мы можем обучить алгоритм классификации,
используя векторы, полученные в ходе работы алгоритма, в качестве входных
данных модели. Будет обучать модель на дополнительных размеченных данных,
которые содержат пары из идентификатора сообщества и его категории.

В качестве алгоритма классификации я использовал gradient boosting (TODO:
другие алгоритмы). Обученная модель показала следующие
результаты на тестовом наборе данных:

TODO: таблица с результатами, сравнение с другими моделями

\section{Дополнительные подзадачи}

TODO

%% Макрос для заключения. Совместим со старым стилевиком.
\startconclusionpage

TODO

\printmainbibliography

%% После этой команды chapter будет генерировать приложения, нумерованные русскими буквами.
%% \startappendices из старого стилевика будет делать то же самое
\appendix

\end{document}
